# Classificador de Acidentes de Tr√¢nsito

Aplica√ß√£o web desenvolvida em Django para classifica√ß√£o de imagens de acidentes de tr√¢nsito utilizando algoritmo Naive Bayes.

## üìã Vis√£o Geral

O projeto consiste em tr√™s partes principais:

1. **Prepara√ß√£o do Dataset**: Notebooks que fazem download e aumento de dados (data augmentation) das imagens de treinamento

2. **Treinamento do Modelo**: Notebook Jupyter que treina um classificador Naive Bayes para identificar tr√™s categorias de imagens:
   - Acidentes de tr√¢nsito graves
   - Acidentes de tr√¢nsito moderados
   - N√£o acidentes

3. **Aplica√ß√£o Web**: Interface Django que permite upload de imagens e retorna a predi√ß√£o do modelo treinado.

## üóÇÔ∏è Estrutura do Projeto

```
project-naive-bayes-web/
‚îú‚îÄ‚îÄ dataset_preprocessing/         # Prepara√ß√£o do dataset
‚îÇ   ‚îú‚îÄ‚îÄ data_download.ipynb       # Download de imagens via Bing
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.ipynb  # Data augmentation
‚îÇ   ‚îî‚îÄ‚îÄ dataset/                  # Imagens originais baixadas
‚îÇ       ‚îú‚îÄ‚îÄ dataset_severe_accident/
‚îÇ       ‚îú‚îÄ‚îÄ dataset_moderate_accident/
‚îÇ       ‚îî‚îÄ‚îÄ dataset_no_accident/
‚îÇ
‚îú‚îÄ‚îÄ naive_bayes_training/          # Treinamento do modelo
‚îÇ   ‚îú‚îÄ‚îÄ train_model.ipynb          # Notebook de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ dataset_finalized/        # Dataset aumentado com ~720 imagens
‚îÇ       ‚îú‚îÄ‚îÄ dataset_final_severe_accident/
‚îÇ       ‚îú‚îÄ‚îÄ dataset_final_moderate_accident/
‚îÇ       ‚îî‚îÄ‚îÄ dataset_final_no_accident/
‚îÇ
‚îî‚îÄ‚îÄ website/                       # Aplica√ß√£o Django
    ‚îú‚îÄ‚îÄ manage.py
    ‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias do projeto
    ‚îú‚îÄ‚îÄ config/                    # Configura√ß√µes do Django
    ‚îú‚îÄ‚îÄ classifier/                # App de classifica√ß√£o
    ‚îÇ   ‚îú‚îÄ‚îÄ views.py              # L√≥gica de upload e predi√ß√£o
    ‚îÇ   ‚îú‚îÄ‚îÄ utils.py              # Carregamento do modelo e features
    ‚îÇ   ‚îú‚îÄ‚îÄ templates/            # HTMLs (index e result)
    ‚îÇ   ‚îî‚îÄ‚îÄ static/               # CSS e imagens
    ‚îî‚îÄ‚îÄ ml_models/                # Modelo e scaler salvos
        ‚îú‚îÄ‚îÄ modelo_ia.pkl
        ‚îî‚îÄ‚îÄ scaler.pkl
```

## üöÄ Como Executar o Projeto

### Pr√©-requisitos

- Python 3.8+
- pip

### 1. Configurar o Ambiente Virtual

Navegue at√© a pasta `website`:

```powershell
cd website
```

Crie o ambiente virtual:

```powershell
python -m venv .venv
```

Ative o ambiente virtual:

```powershell
.\.venv\Scripts\Activate.ps1
```

### 2. Instalar Depend√™ncias

```powershell
pip install -r requirements.txt
```

As depend√™ncias incluem:
- Django 6.0.1
- numpy 2.2.6
- opencv-python 4.12.0.88
- scikit-image 0.26.0
- scikit-learn 1.8.0
- Pillow 12.1.0

### 3. Executar o Servidor

```powershell
python manage.py runserver
```

Acesse a aplica√ß√£o em: **http://127.0.0.1:8000/**

## üß† Fluxo de Funcionamento

### Fase 0: Prepara√ß√£o do Dataset

#### 0.1 Download de Imagens (`data_download.ipynb`)

1. **Instala√ß√£o**: `pip install icrawler opencv-python pandas`

2. **Download Automatizado**: Usa Bing Image Crawler para baixar ~250 imagens por categoria:
   - `dataset_severe_accident`: Carros totalmente destru√≠dos, capotados, colis√µes graves
   - `dataset_moderate_accident`: Amassados, arranh√µes, lanternas quebradas
   - `dataset_no_accident`: Carros normais em diferentes contextos

3. **Estrat√©gia Inteligente**:
   - 5-6 termos de busca por categoria (ingl√™s e portugu√™s)
   - 50 imagens por termo
   - Total: ~750-900 imagens originais

4. **Processamento em CSV** (opcional):
   - Converte imagens para 64x64 pixels em escala de cinza
   - Vetoriza em 4096 valores
   - Salva em `dataset/dados_acidentes.csv`

5. **Sa√≠da**: Imagens salvas em `dataset_preprocessing/dataset/dataset_*_accident/`

#### 0.2 Aumento de Dados (`data_preprocessing.ipynb`)

1. **Instala√ß√£o**: `pip install tensorflow opencv-python matplotlib numpy`

2. **Data Augmentation**: Aplica 4 transforma√ß√µes em cada imagem original:
   - ‚úÖ Original (sem altera√ß√£o)
   - ‚úÖ Flip horizontal (espelhamento)
   - ‚úÖ Ajuste de tom/matiz (hue adjustment)
   - ‚úÖ Flip + ajuste de tom

3. **Multiplica√ß√£o do Dataset**: Cada imagem vira 4 varia√ß√µes
   - ~250 imagens ‚Üí ~1000 imagens por categoria
   - Total: ~3000-3600 imagens

4. **Normaliza√ß√£o**: Garante que todas as imagens est√£o no range [0, 1]

5. **Sa√≠da**: Imagens processadas em `naive_bayes_training/dataset_finalized/`
   - `dataset_final_severe_accident/`
   - `dataset_final_moderate_accident/`
   - `dataset_final_no_accident/`

---

### Fase 1: Treinamento do Modelo

1. **Dataset**: Dataset aumentado (gerado na Fase 0) com centenas de imagens por classe
   - `dataset_final_severe_accident/`
   - `dataset_final_moderate_accident/`
   - `dataset_final_no_accident/`

2. **Extra√ß√£o de Features**: O notebook `train_model.ipynb` processa cada imagem e extrai 8112 caracter√≠sticas:
   - **HOG** (8100 features): Histogram of Oriented Gradients para detec√ß√£o de formas
   - **Canny** (1 feature): Densidade de bordas
   - **Harris** (1 feature): Densidade de cantos
   - **LBP** (10 features): Local Binary Pattern para textura

3. **Pr√©-processamento**:
   - Redimensionamento para 128x128 pixels
   - Convers√£o para escala de cinza
   - Normaliza√ß√£o com StandardScaler

4. **Treinamento**:
   - Algoritmo: Gaussian Naive Bayes
   - Split: 80% treino / 20% teste
   - Acur√°cia alcan√ßada: ~76%

5. **Salvamento**:
   - `modelo_ia.pkl`: Modelo treinado
   - `scaler.pkl`: StandardScaler ajustado

### Fase 2: Aplica√ß√£o Web

1. **Upload de Imagem**:
   - Usu√°rio acessa a p√°gina inicial
   - Seleciona uma imagem para an√°lise
   - Clica em "Prever"

2. **Processamento** (`classifier/utils.py`):
   - Carrega modelo e scaler (lazy loading)
   - L√™ imagem em escala de cinza
   - Extrai 8112 features (mesmo pipeline do treinamento)
   - Normaliza features com o scaler
   - Faz predi√ß√£o com o modelo

3. **Resultado**:
   - Classe predita √© mapeada para texto leg√≠vel
   - Exibe resultado na p√°gina de resultados

## üéØ Detalhes T√©cnicos

### Extra√ß√£o de Features

```python
# Mesma fun√ß√£o usada no treinamento e na predi√ß√£o
def extrair_features_avancadas(img_array):
    img = cv2.resize(img_array, (128, 128))
    
    # HOG
    features_hog = hog(img, orientations=9, pixels_per_cell=(8,8),
                       cells_per_block=(2,2))
    
    # Bordas (Canny)
    edges = cv2.Canny(img, 100, 200)
    densidade_bordas = [np.sum(edges > 0) / edges.size]
    
    # Cantos (Harris)
    dst = cv2.cornerHarris(img, 2, 3, 0.04)
    densidade_cantos = [np.sum(dst > 0.01 * dst.max()) / dst.size]
    
    # Textura (LBP)
    lbp = local_binary_pattern(img, 8, 1, method="uniform")
    hist_lbp = np.histogram(lbp.ravel(), bins=10, range=(0,10), density=True)[0]
    
    return np.hstack([features_hog, densidade_bordas, densidade_cantos, hist_lbp])
```

### Mapeamento de Classes

| Valor | Classe |
|-------|--------|
| 0 | Acidente de tr√¢nsito grave |
| 1 | Acidente de tr√¢nsito moderado |
| 2 | N√£o √© acidente |

## üìä M√©tricas de Desempenho

- **Precis√£o M√©dia**: 76%
- **Total de Features**: 8112
- **Tempo de Predi√ß√£o**: ~1-2 segundos por imagem

## üîÑ Fluxo Completo de Retreinamento

Para retreinar o modelo do zero:

### Op√ß√£o 1: Com Download de Novas Imagens

1. **Preparar Dataset**:
   ```powershell
   cd dataset_preprocessing
   # Execute data_download.ipynb (download de imagens)
   # Execute data_preprocessing.ipynb (data augmentation)
   ```

2. **Treinar Modelo**:
   ```powershell
   cd ../naive_bayes_training
   # Execute train_model.ipynb
   ```

3. **Atualizar Aplica√ß√£o**:
   - Os arquivos `modelo_ia.pkl` e `scaler.pkl` s√£o salvos em `website/ml_models/`
   - Reinicie o servidor Django

### Op√ß√£o 2: Apenas Adicionar Imagens Manualmente

1. Adicione imagens diretamente em `dataset_preprocessing/dataset/dataset_*_accident/`
2. Execute `data_preprocessing.ipynb` para aumentar as novas imagens
3. Execute `train_model.ipynb` para retreinar
4. Reinicie o servidor Django

## üõ†Ô∏è Tecnologias Utilizadas

- **Backend**: Django 6.0.1
- **Machine Learning**: scikit-learn (Gaussian Naive Bayes)
- **Processamento de Imagens**: OpenCV, scikit-image
- **Frontend**: HTML5, CSS3
- **Ambiente de Treinamento**: Jupyter Notebook

## Equipe

- Hiel Saraiva
- Roberta Alanis
- Jo√£o Marcelo Pimenta
- Ryan Leite
- Ruan Ven√¢ncio
